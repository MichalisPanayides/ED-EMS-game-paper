\subsection{Building the game}\label{sec:methodology}

The problem defined in this section describes a normal-form
game between the decision makers of two hospitals and a third player, the 
ambulance service, that 
decides how to distribute individuals to the two systems.
The strategy space of the two hospitals is defined as the possible values
that the threshold parameter can take \(T_i \in [1, N_i]\).
Then, the ambulance service has to decide on the proportion of individuals to 
send to 
each hospital \(p_A \text{ and } p_B\), where \(p_A, p_B \in [0, 1] \)
and \(p_A + p_B = 1\).
In practice this would correspond to a learned behaviour through experience of
waiting at each hospital.
Figure \ref{fig:imperfect_info_game} 
shows a diagrammatic representation of the game to be played and the decisions 
to be made.
As described in section \ref{sec:model_overview}, hospital \(A\) decides
on a strategy and at the same time, hospital \(B\) chooses its own 
threshold but unaware of the first hospital's choice.
Finally, the ambulance service makes its choice based on the strategies that the 
hospitals chose to play. 

The utilities to each player can be represented by 3 matrices; the two payoff 
matrices of the normal form game and the routing matrix.
The payoff matrices and their utilities are defined by equations 
(\ref{eq:payoff_entry}) and (\ref{eq:payoff_matrices}).

The routing matrix holds the values \((p_A, p_B)\) which are the proportion 
of ambulance patients to send to queueing systems \(A\) and \(B\).
Each pair \((p_A, p_B)\) can be calculated using equation 
(\ref{eq:obj_distributor}) and is essentially
a best response to the actions of the hospitals.
Thus, using equation (\ref{eq:obj_distributor}) for all possible sets of 
thresholds we can get the full routing matrix that consists of the proportions
to send to hospital A (\(p_A\)) and to hospital B (\(p_B\)).

\begin{equation}\label{eq:routing_matrix}
    R = 
    \begin{pmatrix}
        (p_{1,1}^A, p_{1,1}^B) & (p_{1,2}^A, p_{1,2}^B) & \dots & 
        (p_{1,N_B}^A, p_{1,N_B}^B) \\
        (p_{2,1}^A, p_{2,1}^B) & (p_{2,2}^A, p_{2,2}^B) & \dots & 
        (p_{2,N_B}^A, p_{2,N_B}^B) \\
        \vdots & \vdots & \ddots & \vdots \\
        (p_{N_A,1}^A, p_{N_A,1}^B) & (p_{N_A,2}^A, p_{N_A,2}^B) & \dots & 
        (p_{N_A,N_B}^A, p_{N_A,N_B}^B) \\
    \end{pmatrix}
\end{equation}

Note that since \(p_{i,j}^A + p_{i,j}^B = 1\) the routing matrix needs only to
store one of the two values; either \(p_{i,j}^A\) or \(p_{i,j}^B\).
Thus, the routing matrix \(R\) can be simplified to:

\begin{equation}\label{eq:routing_matrix_simplified}
    R = 
    \begin{pmatrix}
        p_{1,1}^A & p_{1,2}^A & \dots & p_{1,N_B}^A \\
        p_{2,1}^A & p_{2,2}^A & \dots & p_{2,N_B}^A \\
        \vdots & \vdots & \ddots & \vdots \\
        p_{N_A,1}^A & p_{N_A,2}^A & \dots & p_{N_A,N_B}^A \\
    \end{pmatrix}
\end{equation}

The game can thus be partitioned into a normal form game between the
two hospitals and then finding the ambulance service's best strategy. 

Consider Figure \ref{fig:imperfect_info_game} and the flow of the game that was
described (i.e. \(H_A, H_B \rightarrow D\)).
Due to the fact that the payoff matrices \(A\) and \(B\) depend on the routing 
matrix \(R\) the entries of the matrices are calculated in a backwards way 
(\(D \rightarrow H_A, H_B\)). 
This is done using backwards induction. 
For each action choice of the hospitals, first solve the game from the
ambulance's point of view.
This in effect results in a 2-player normal form game representing the
hospital's point of view.
Thus, for every pair of strategies \(T_A, T_B\), the values of \(p_A\) and 
\(p_B\) that satisfy equation (\ref{eq:obj_distributor}) are found
numerically using Brent's bisection algorithm~\cite{brent1973algorithms}.
Each pair \((p_A, p_B)\) corresponds to the best response of the ambulance
service to the two hospitals' played strategies.
Finally, using the routing matrix, equation (\ref{eq:payoff_entry}) can also be
used to populate the payoff matrices of the hospitals since we now know the 
arrival rate of each hospital.

Having calculated the payoff matrices \(A\) and \(B\), several algorithms can 
be used to measure some form of the emergent behaviour.
One possibility would be to compute the Nash equilibrium
which is the point of the game were both players have no 
incentive to deviate from their played strategies \cite{kreps1989nash}.
In other words their chosen strategies are a best response to each other.
Computation of Nash equilibria can be done in a relatively efficient way using 
the Lemke Howson algorithm~\cite{LemkeHowson}.
Lemke-Howson uses best response polytopes to get one of the Nash equilibrium of
the game. 
Other algorithms exists that will compute all Nash equilibria but 
for large games the computational complexity becomes problematic.
All game theoretic calculations were done in Python using the Nashpy library 
\cite{thenashpyproject}.

Another approach to measuring emergent behaviour is to consider 
the emergence itself and not only stable end points. 
Indeed, some Nash equilibria might not arise naturally. 
Thus in order to analyse the strategies played by the two hospitals, the 
learning 
algorithm asymmetric replicator dynamics is 
used~\cite{asymmetricreplicatordynamics}.
The two hospitals are modelled as two separate populations where each 
individual in the population is assigned a strategy.
As the game progresses the proportion of each player playing each strategy 
changes based on their previous interactions.
The fitness of each strategy is defined as:

\begin{equation}\label{eq:asymmetric_fitness}
    f_x = Ay, \quad f_y = x^T B
\end{equation}

Here, \(x \in \mathbb{R}^{m \times 1} \) and
\(y \in \mathbb{R}^{n \times 1}\) correspond to the proportion of individuals 
that play each strategy in each population.
Similarly, the average fitness of each strategy is given by:
\begin{equation}
    \phi_x = f_x x^T, \quad \phi_y = f_y y
\end{equation}

The rate of change of strategy \( i \) of both types of individuals is captured 
by:
\begin{equation}
    \frac{dx}{dt}_i = x_i((f_x)_i - \phi_x), \quad \text{ for all }i
\end{equation}

\begin{equation}
    \frac{dy}{dt}_i = y_i((f_y)_i - \phi_y), \quad \text{ for all }i
\end{equation}
 
In addition to asymmetric replicator dynamics, the learning algorithms
fictitious play and stochastic fictitious play \cite{fudenberg1998theory}
were used.